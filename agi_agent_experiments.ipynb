{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyO7iB//mUP86UHwHxyg9t9o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Pinn/blob/main/agi_agent_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYuI5jEtgQm8"
      },
      "outputs": [],
      "source": [
        "# %% [markdown]\n",
        "# # AGI Agent: Multi-Task Experimental Harness\n",
        "# Safe defaults, reproducibility, and hot-swappable modules.\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 0. Setup and provenance\n",
        "\n",
        "import os, sys, math, random, time, json, dataclasses, typing as T\n",
        "from dataclasses import dataclass, field\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    TORCH_AVAILABLE = True\n",
        "except Exception:\n",
        "    TORCH_AVAILABLE = False\n",
        "\n",
        "# --- Reproducibility ---\n",
        "SEED = 1234\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "if TORCH_AVAILABLE:\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "DEVICE = \"cuda\" if TORCH_AVAILABLE and torch.cuda.is_available() else \"cpu\"\n",
        "RUN_ID = f\"run_{int(time.time())}\"\n",
        "os.makedirs(\"runs\", exist_ok=True)\n",
        "\n",
        "def log_jsonl(path: str, record: dict):\n",
        "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "print({\"seed\": SEED, \"device\": DEVICE, \"torch\": TORCH_AVAILABLE, \"run_id\": RUN_ID})\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 1. Configs and agent adapter\n",
        "\n",
        "@dataclass\n",
        "class EvalConfig:\n",
        "    # Regression\n",
        "    n_reg_train: int = 5\n",
        "    n_reg_test: int = 2\n",
        "    k_shot: int = 5\n",
        "    q_points: int = 50\n",
        "\n",
        "    # Multimodal\n",
        "    mm_trials: int = 3\n",
        "    mm_candidates: int = 4\n",
        "\n",
        "    # Grid navigation\n",
        "    grid_trials: int = 5\n",
        "    grid_max_steps: int = 20\n",
        "\n",
        "@dataclass\n",
        "class AgentConfig:\n",
        "    name: str = \"SimpleAgent\"\n",
        "    use_world_model: bool = False\n",
        "    use_multimodal_encoder: bool = True\n",
        "    mc_dropout_passes: int = 10\n",
        "    reflection_steps: int = 1\n",
        "    notes: str = \"\"\n",
        "\n",
        "class AgentAdapter:\n",
        "    def __init__(self, cfg: AgentConfig):\n",
        "        self.cfg = cfg\n",
        "\n",
        "    def act(self, obs: dict, task_id: str, step: int, state: dict | None):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def learn(self, batch: dict, task_id: str) -> dict:\n",
        "        return {\"learned\": False}\n",
        "\n",
        "    def reflect(self, logs: list[dict]) -> dict:\n",
        "        return {\"notes\": \"no-op reflection\", \"patches\": {}}\n",
        "\n",
        "    def encode(self, modality: str, data) -> np.ndarray:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def imagine(self, state: dict, n_steps: int = 5) -> list[dict]:\n",
        "        return []\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 2. Instantiate configs and agent\n",
        "\n",
        "eval_cfg = EvalConfig()\n",
        "\n",
        "class DummyAgentAdapter(AgentAdapter):\n",
        "    \"\"\"\n",
        "    A minimal agent adapter that can handle:\n",
        "      - txt2img: choose an image index\n",
        "      - img2txt: choose a text index\n",
        "      - regression: return zero predictions\n",
        "    Always returns Python ints for indices to avoid NumPy/PyTorch scalar issues.\n",
        "    \"\"\"\n",
        "\n",
        "    def act(self, obs: dict, task_id: str, step: int, state: dict | None):\n",
        "        mode = obs.get(\"mode\")\n",
        "\n",
        "        # Multimodal: text -> image\n",
        "        if mode == \"txt2img\":\n",
        "            # Always pick the first image (safe dummy)\n",
        "            pred_idx = 0\n",
        "            return pred_idx, state, {}\n",
        "\n",
        "        # Multimodal: image -> text\n",
        "        elif mode == \"img2txt\":\n",
        "            # Always pick the first text (safe dummy)\n",
        "            pred_idx = 0\n",
        "            return pred_idx, state, {}\n",
        "\n",
        "        # Simple regression task\n",
        "        elif \"x\" in obs:\n",
        "            import numpy as np\n",
        "            x = obs[\"x\"]\n",
        "            preds = np.zeros_like(x, dtype=float)\n",
        "            return preds, state, {}\n",
        "\n",
        "        # Default: no action\n",
        "        return None, state, {}\n",
        "\n",
        "    def learn(self, batch: dict, task_id: str) -> dict:\n",
        "        return {\"learned\": True}\n",
        "\n",
        "    def encode(self, modality: str, data):\n",
        "        return np.zeros(8)\n",
        "\n",
        "agent_cfg = AgentConfig(\n",
        "    name=\"SimpleAgent\",\n",
        "    use_world_model=False,\n",
        "    use_multimodal_encoder=True,\n",
        "    mc_dropout_passes=10,\n",
        "    reflection_steps=1,\n",
        "    notes=\"baseline\"\n",
        ")\n",
        "\n",
        "agent = DummyAgentAdapter(agent_cfg)\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3. Example: generate tasks and run regression episodes\n",
        "\n",
        "# These functions must exist in your environment\n",
        "# generate_sin_tasks(seed) -> (train_tasks, test_tasks)\n",
        "# run_regression_episode(agent, task, k_shot, q_points, split) -> dataclass result\n",
        "\n",
        "sin_train, sin_test = generate_sin_tasks(SEED)\n",
        "\n",
        "records = []\n",
        "for task in sin_train[:eval_cfg.n_reg_train]:\n",
        "    r = run_regression_episode(\n",
        "        agent,\n",
        "        task,\n",
        "        k_shot=eval_cfg.k_shot,\n",
        "        q_points=eval_cfg.q_points,\n",
        "        split=\"train\"\n",
        "    )\n",
        "    run_id = f\"run_{int(time.time())}\"\n",
        "    records.append(dataclasses.asdict(r) | {\"run_id\": RUN_ID})\n",
        "\n",
        "# Optional: test loop\n",
        "for task in sin_test[:eval_cfg.n_reg_test]:\n",
        "    r = run_regression_episode(\n",
        "        agent,\n",
        "        task,\n",
        "        k_shot=eval_cfg.k_shot,\n",
        "        q_points=eval_cfg.q_points,\n",
        "        split=\"test\"\n",
        "    )\n",
        "    run_id = f\"run_{int(time.time())}\"\n",
        "    records.append(dataclasses.asdict(r) | {\"run_id\": RUN_ID})\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 1.1 Simple, runnable baseline agent (replace with yours)\n",
        "# - Symbol/Grid: heuristic + epsilon-random\n",
        "# - Regression: small MLP with optional MAML-like inner loop\n",
        "# - Multimodal: tiny text/image encoders for synthetic data\n",
        "# This keeps the harness runnable end-to-end until you plug in your modules.\n",
        "\n",
        "# %%\n",
        "class SimpleAgentAdapter(AgentAdapter):\n",
        "    def __init__(self, cfg: AgentConfig):\n",
        "        super().__init__(cfg)\n",
        "        self.global_step = 0\n",
        "        self.eps = 0.1\n",
        "\n",
        "        # --- Text encoder setup ---\n",
        "        self.char_vocab = {c: i+1 for i, c in enumerate(\"abcdefghijklmnopqrstuvwxyz0123456789_- \")}\n",
        "        self.txt_dim = 64  # bag-of-chars output size\n",
        "\n",
        "        # --- Image encoder setup ---\n",
        "        self.img_size = (32, 32)\n",
        "        self.img_dim = self.img_size[0] * self.img_size[1]  # grayscale flatten\n",
        "\n",
        "        # --- Shared multimodal embedding dimension ---\n",
        "        self.shared_dim = 64\n",
        "\n",
        "        if TORCH_AVAILABLE:\n",
        "            # Trainable projections into shared space\n",
        "            self.txt_proj = nn.Linear(self.txt_dim, self.shared_dim)\n",
        "            self.img_proj = nn.Linear(self.img_dim, self.shared_dim)\n",
        "\n",
        "            # Regression model\n",
        "            self.reg_model = nn.Sequential(\n",
        "                nn.Linear(1, 64), nn.ReLU(),\n",
        "                nn.Linear(64, 64), nn.ReLU(),\n",
        "                nn.Dropout(p=0.1),\n",
        "                nn.Linear(64, 1)\n",
        "            ).to(DEVICE)\n",
        "\n",
        "            # Optimizers\n",
        "            self.reg_opt = torch.optim.Adam(self.reg_model.parameters(), lr=5e-3)\n",
        "            self.mm_opt = torch.optim.Adam(\n",
        "                list(self.txt_proj.parameters()) + list(self.img_proj.parameters()),\n",
        "                lr=1e-3\n",
        "            )\n",
        "        else:\n",
        "            self.reg_model = None\n",
        "            self.txt_proj = None\n",
        "            self.img_proj = None\n",
        "\n",
        "    def act(self, obs: dict, task_id: str, step: int, state: dict | None):\n",
        "        self.global_step += 1\n",
        "\n",
        "        if task_id.startswith(\"grid\"):\n",
        "            acts = obs[\"action_space\"]\n",
        "            if random.random() < self.eps:\n",
        "                a = random.choice(acts)\n",
        "            else:\n",
        "                goal = obs.get(\"goal\")\n",
        "                pos = obs[\"pos\"]\n",
        "                def heuristic(act):\n",
        "                    dx, dy = {\"up\": (-1, 0), \"down\": (1, 0), \"left\": (0, -1), \"right\": (0, 1)}.get(act, (0, 0))\n",
        "                    np_next = (pos[0] + dx, pos[1] + dy)\n",
        "                    if goal:\n",
        "                        return - (abs(np_next[0] - goal[0]) + abs(np_next[1] - goal[1]))\n",
        "                    return -random.random()\n",
        "                a = min(acts, key=heuristic)\n",
        "            return a, state or {}, {}\n",
        "\n",
        "        elif task_id.startswith(\"symbol\"):\n",
        "            rules = obs[\"rules\"]; cur = obs[\"string\"]; target = obs[\"target\"]\n",
        "            candidates = []\n",
        "            for (lhs, rhs) in rules:\n",
        "                idx = cur.find(lhs)\n",
        "                if idx >= 0:\n",
        "                    new_s = cur[:idx] + rhs + cur[idx+len(lhs):]\n",
        "                    candidates.append((lhs, rhs, new_s))\n",
        "            if candidates:\n",
        "                def score(c):\n",
        "                    s = c[2]\n",
        "                    return abs(len(s) - len(target)) + sum(1 for a, b in zip(s, target) if a != b)\n",
        "                lhs, rhs, _ = min(candidates, key=score)\n",
        "                return (lhs, rhs), state or {}, {}\n",
        "            else:\n",
        "                if rules:\n",
        "                    return random.choice(rules), state or {}, {}\n",
        "                return None, state or {}, {}\n",
        "\n",
        "        elif task_id.startswith(\"regress\"):\n",
        "            x = obs[\"x\"]\n",
        "            if TORCH_AVAILABLE and self.reg_model is not None:\n",
        "                with torch.no_grad():\n",
        "                    self.reg_model.train(False)\n",
        "                    pred = self.reg_model(torch.from_numpy(x).float().to(DEVICE)).cpu().numpy()\n",
        "                    self.reg_model.train(True)\n",
        "                return pred, state or {}, {}\n",
        "            else:\n",
        "                return np.zeros_like(x), state or {}, {}\n",
        "\n",
        "        elif task_id.startswith(\"multimodal\"):\n",
        "            if obs[\"mode\"] == \"txt2img\":\n",
        "                q = self._encode_text(obs[\"text\"])\n",
        "                sims = [self._cos(q, self._encode_img(img)) for img in obs[\"images\"]]\n",
        "                idx = int(np.argmax(sims))\n",
        "                return idx, state or {}, {}\n",
        "            else:\n",
        "                q = self._encode_img(obs[\"image\"])\n",
        "                sims = [self._cos(q, self._encode_text(t)) for t in obs[\"texts\"]]\n",
        "                idx = int(np.argmax(sims))\n",
        "                return idx, state or {}, {}\n",
        "\n",
        "        else:\n",
        "            return None, state or {}, {}\n",
        "\n",
        "    def learn(self, batch: dict, task_id: str) -> dict:\n",
        "        if TORCH_AVAILABLE:\n",
        "            if task_id.startswith(\"regress\") and self.reg_model is not None:\n",
        "                x = torch.from_numpy(batch[\"x\"]).float().to(DEVICE)\n",
        "                y = torch.from_numpy(batch[\"y\"]).float().to(DEVICE)\n",
        "                self.reg_opt.zero_grad()\n",
        "                pred = self.reg_model(x)\n",
        "                loss = F.mse_loss(pred, y)\n",
        "                loss.backward()\n",
        "                self.reg_opt.step()\n",
        "                return {\"loss\": float(loss.item())}\n",
        "\n",
        "            elif task_id.startswith(\"multimodal\") and self.txt_proj is not None:\n",
        "                # Example: simple contrastive-like loss for matching\n",
        "                mode = batch.get(\"mode\")\n",
        "                if mode == \"txt2img\":\n",
        "                    txt_emb = self._encode_text(batch[\"text\"], torch_out=True)\n",
        "                    img_embs = torch.stack([self._encode_img(im, torch_out=True) for im in batch[\"images\"]])\n",
        "                    sims = F.cosine_similarity(txt_emb.unsqueeze(0), img_embs)\n",
        "                    target_idx = batch[\"target_idx\"]\n",
        "                    loss = F.cross_entropy(sims.unsqueeze(0), torch.tensor([target_idx], device=DEVICE))\n",
        "                else:\n",
        "                    img_emb = self._encode_img(batch[\"image\"], torch_out=True)\n",
        "                    txt_embs = torch.stack([self._encode_text(t, torch_out=True) for t in batch[\"texts\"]])\n",
        "                    sims = F.cosine_similarity(img_emb.unsqueeze(0), txt_embs)\n",
        "                    target_idx = batch[\"target_idx\"]\n",
        "                    loss = F.cross_entropy(sims.unsqueeze(0), torch.tensor([target_idx], device=DEVICE))\n",
        "\n",
        "                self.mm_opt.zero_grad()\n",
        "                loss.backward()\n",
        "                self.mm_opt.step()\n",
        "                return {\"loss\": float(loss.item())}\n",
        "\n",
        "        return {\"loss\": None}\n",
        "\n",
        "    def reflect(self, logs: list[dict]) -> dict:\n",
        "        fail_rate = np.mean([1.0 if r.get(\"success\") == 0 else 0.0 for r in logs if \"success\" in r]) if logs else 0.0\n",
        "        if fail_rate > 0.5:\n",
        "            self.eps = min(0.3, self.eps + 0.05)\n",
        "            note = f\"Increased epsilon to {self.eps:.2f} after fail_rate={fail_rate:.2f}\"\n",
        "        else:\n",
        "            note = f\"No change; fail_rate={fail_rate:.2f}\"\n",
        "        return {\"notes\": note, \"patches\": {\"eps\": self.eps}}\n",
        "\n",
        "    def encode(self, modality: str, data) -> np.ndarray:\n",
        "        if modality == \"text\":\n",
        "            return self._encode_text(data)\n",
        "        elif modality == \"image\":\n",
        "            return self._encode_img(data)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown modality: {modality}\")\n",
        "\n",
        "    # --- helpers ---\n",
        "    def _encode_text(self, s: str, torch_out=False):\n",
        "        idxs = [self.char_vocab.get(c.lower(), 0) for c in s]\n",
        "        vec = np.zeros(self.txt_dim, dtype=np.float32)\n",
        "        for i in idxs:\n",
        "            vec[i % self.txt_dim] += 1.0\n",
        "        vec = vec / (np.linalg.norm(vec) + 1e-8)\n",
        "\n",
        "        if TORCH_AVAILABLE:\n",
        "            tvec = torch.from_numpy(vec).float().to(DEVICE)\n",
        "            proj = self.txt_proj(tvec)\n",
        "            return proj if torch_out else proj.detach().cpu().numpy()\n",
        "        else:\n",
        "            return vec\n",
        "\n",
        "    def _encode_img(self, img: np.ndarray, torch_out=False):\n",
        "        from skimage.transform import resize\n",
        "        small = resize(img, self.img_size, anti_aliasing=True, preserve_range=True).astype(np.float32)\n",
        "        vec = small.mean(axis=2).reshape(-1)\n",
        "        vec = vec / (np.linalg.norm(vec) + 1e-8)\n",
        "\n",
        "        if TORCH_AVAILABLE:\n",
        "            tvec = torch.from_numpy(vec).float().to(DEVICE)\n",
        "            proj = self.img_proj(tvec)\n",
        "            return proj if torch_out else proj.detach().cpu().numpy()\n",
        "        else:\n",
        "            return vec\n",
        "\n",
        "    @staticmethod\n",
        "    def _cos(a: np.ndarray, b: np.ndarray) -> float:\n",
        "        return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b) + 1e-8))\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 2. Tasks\n",
        "# - Symbol puzzles (neurosymbolic)\n",
        "# - Grid navigation (spatial + memory)\n",
        "# - Few-shot regression (meta-learning baseline)\n",
        "# - Multimodal matching (grounding)\n",
        "\n",
        "# %%\n",
        "@dataclass\n",
        "class EpisodeResult:\n",
        "    task_id: str\n",
        "    split: str\n",
        "    success: int\n",
        "    steps: int\n",
        "    reward: float\n",
        "    meta: dict = field(default_factory=dict)\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 2.1 Symbol puzzles\n",
        "\n",
        "# %%\n",
        "@dataclass\n",
        "class SymbolTask:\n",
        "    rules: list[tuple[str,str]]\n",
        "    start: str\n",
        "    target: str\n",
        "    max_steps: int = 12\n",
        "\n",
        "def run_symbol_episode(agent: AgentAdapter, task: SymbolTask, split=\"train\") -> EpisodeResult:\n",
        "    s = task.start\n",
        "    for t in range(task.max_steps):\n",
        "        obs = {\"rules\": task.rules, \"string\": s, \"target\": task.target}\n",
        "        action, _, _ = agent.act(obs, task_id=\"symbol/rewrite\", step=t, state=None)\n",
        "        if action is None: break\n",
        "        lhs, rhs = action\n",
        "        idx = s.find(lhs)\n",
        "        if idx >= 0:\n",
        "            s = s[:idx] + rhs + s[idx+len(lhs):]\n",
        "        if s == task.target:\n",
        "            return EpisodeResult(\"symbol/rewrite\", split, 1, t+1, reward=1.0, meta={\"final\": s})\n",
        "    return EpisodeResult(\"symbol/rewrite\", split, 0, task.max_steps, reward=0.0, meta={\"final\": s})\n",
        "\n",
        "def generate_symbol_dataset(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    train, test = [], []\n",
        "    # Train rules emphasize short compositions; test holds out longer compositions and new rule combos\n",
        "    base_rules = [(\"A\",\"AB\"),(\"B\",\"BA\"),(\"BA\",\"A\"),(\"AA\",\"B\"),(\"BB\",\"A\")]\n",
        "    for _ in range(50):\n",
        "        start = random.choice([\"A\",\"B\",\"AB\",\"BA\"])\n",
        "        target = random.choice([\"ABA\",\"BAB\",\"ABAB\",\"BAA\",\"ABB\"])\n",
        "        rules = random.sample(base_rules, k=3)\n",
        "        train.append(SymbolTask(rules, start, target))\n",
        "    for _ in range(20):\n",
        "        start = random.choice([\"A\",\"B\",\"AB\",\"BA\"])\n",
        "        target = random.choice([\"ABABA\",\"BABAB\",\"BAAB\"])\n",
        "        # Hold-out rules combos\n",
        "        rules = random.sample(base_rules[::-1], k=3)\n",
        "        test.append(SymbolTask(rules, start, target, max_steps=16))\n",
        "    return train, test\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 2.2 Grid navigation\n",
        "\n",
        "# %%\n",
        "@dataclass\n",
        "class GridTask:\n",
        "    grid_size: int = 7\n",
        "    obstacles: list[tuple[int,int]] = field(default_factory=list)\n",
        "    keys: list[tuple[int,int]] = field(default_factory=list)\n",
        "    start: tuple[int,int] = (0,0)\n",
        "    goal: tuple[int,int] = (6,6)\n",
        "    max_steps: int = 40\n",
        "    require_key: bool = False\n",
        "\n",
        "ACTIONS = [\"up\",\"down\",\"left\",\"right\"]\n",
        "DELTAS = {\"up\":(-1,0),\"down\":(1,0),\"left\":(0,-1),\"right\":(0,1)}\n",
        "\n",
        "def run_grid_episode(agent: AgentAdapter, task: GridTask, split=\"train\") -> EpisodeResult:\n",
        "    pos = list(task.start)\n",
        "    have_key = False\n",
        "    for t in range(task.max_steps):\n",
        "        obs = {\"pos\": tuple(pos), \"goal\": task.goal, \"action_space\": ACTIONS}\n",
        "        act, _, _ = agent.act(obs, task_id=\"grid/nav\", step=t, state=None)\n",
        "        dx, dy = DELTAS.get(act, (0,0))\n",
        "        npos = (pos[0]+dx, pos[1]+dy)\n",
        "        if 0 <= npos[0] < task.grid_size and 0 <= npos[1] < task.grid_size and npos not in task.obstacles:\n",
        "            pos = list(npos)\n",
        "        if tuple(pos) in task.keys:\n",
        "            have_key = True\n",
        "        if tuple(pos) == task.goal and (not task.require_key or have_key):\n",
        "            return EpisodeResult(\"grid/nav\", split, 1, t+1, 1.0, meta={\"have_key\": have_key})\n",
        "    return EpisodeResult(\"grid/nav\", split, 0, task.max_steps, 0.0, meta={\"have_key\": have_key})\n",
        "\n",
        "def generate_grid_dataset(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    train, test = [], []\n",
        "    def rand_obstacles(gs, count):\n",
        "        obs = set()\n",
        "        while len(obs) < count:\n",
        "            p = (random.randrange(gs), random.randrange(gs))\n",
        "            if p not in [(0,0), (gs-1, gs-1)]: obs.add(p)\n",
        "        return list(obs)\n",
        "    for _ in range(50):\n",
        "        gs = 7\n",
        "        obstacles = rand_obstacles(gs, 8)\n",
        "        task = GridTask(grid_size=gs, obstacles=obstacles, start=(0,0), goal=(gs-1, gs-1), require_key=False)\n",
        "        train.append(task)\n",
        "    for _ in range(20):\n",
        "        gs = 9\n",
        "        obstacles = rand_obstacles(gs, 14)\n",
        "        key = (gs//2, gs//2)\n",
        "        task = GridTask(grid_size=gs, obstacles=obstacles, start=(0,0), goal=(gs-1, gs-1), keys=[key], require_key=True, max_steps=60)\n",
        "        test.append(task)\n",
        "    return train, test\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 2.3 Few-shot regression (sinusoids)\n",
        "\n",
        "# %%\n",
        "@dataclass\n",
        "class SinTask:\n",
        "    amp: float\n",
        "    phase: float\n",
        "    freq: float\n",
        "\n",
        "def sample_sin_task(n: int, task: SinTask, x_range=(-5, 5), noise=0.0) -> tuple[np.ndarray, np.ndarray]:\n",
        "    xs = np.random.uniform(x_range[0], x_range[1], size=(n,1)).astype(np.float32)\n",
        "    ys = task.amp * np.sin(task.freq * xs + task.phase) + noise*np.random.randn(n,1).astype(np.float32)\n",
        "    return xs, ys\n",
        "\n",
        "def generate_sin_tasks(seed=SEED):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    train = [SinTask(amp=float(rng.uniform(0.1, 5.0)), phase=float(rng.uniform(0, np.pi)), freq=float(rng.uniform(0.5, 2.0))) for _ in range(20)]\n",
        "    test = [SinTask(amp=float(rng.uniform(0.1, 5.0)), phase=float(rng.uniform(0, np.pi)), freq=float(rng.uniform(2.0, 3.0))) for _ in range(10)]\n",
        "    return train, test\n",
        "\n",
        "def run_regression_episode(agent: AgentAdapter, task: SinTask, k_shot=10, q_points=50, split=\"train\") -> EpisodeResult:\n",
        "    x_train, y_train = sample_sin_task(k_shot, task)\n",
        "    x_query, y_query = sample_sin_task(q_points, task)\n",
        "    # Pre-adapt loss\n",
        "    pre = agent.act({\"x\": x_query}, task_id=\"regress/sin\", step=0, state=None)[0]\n",
        "    pre_mse = float(np.mean((pre - y_query)**2))\n",
        "    # One simple learn step on support set\n",
        "    metrics = agent.learn({\"x\": x_train, \"y\": y_train}, task_id=\"regress/sin\")\n",
        "    # Post-adapt loss\n",
        "    post = agent.act({\"x\": x_query}, task_id=\"regress/sin\", step=1, state=None)[0]\n",
        "    post_mse = float(np.mean((post - y_query)**2))\n",
        "    return EpisodeResult(\"regress/sin\", split, int(post_mse < pre_mse), steps=1, reward=-post_mse, meta={\"pre_mse\": pre_mse, \"post_mse\": post_mse, \"learn\": metrics})\n",
        "\n",
        "# %% [markdown]\n",
        "# ### 2.4 Multimodal matching (synthetic shapes ↔ text)\n",
        "\n",
        "# %%\n",
        "def make_shape_image(kind: str, color: tuple[int,int,int], size=(64,64)) -> np.ndarray:\n",
        "    # Return HxWxC uint8 image with a centered shape\n",
        "    import cv2\n",
        "    img = np.zeros((size[0], size[1], 3), dtype=np.uint8)\n",
        "    c = (int(color[0]), int(color[1]), int(color[2]))\n",
        "    h, w = size\n",
        "    if kind == \"circle\":\n",
        "        cv2.circle(img, (w//2, h//2), min(h,w)//4, c, -1)\n",
        "    elif kind == \"square\":\n",
        "        s = min(h,w)//3\n",
        "        cv2.rectangle(img, (w//2 - s, h//2 - s), (w//2 + s, h//2 + s), c, -1)\n",
        "    elif kind == \"triangle\":\n",
        "        pts = np.array([[w//2, h//2 - w//4],[w//2 - w//5, h//2 + w//6],[w//2 + w//5, h//2 + w//6]], np.int32)\n",
        "        cv2.fillPoly(img, [pts], c)\n",
        "    return img\n",
        "\n",
        "def generate_multimodal_dataset(seed=SEED):\n",
        "    random.seed(seed)\n",
        "    colors = {\"red\": (220,30,30), \"green\": (30,220,30), \"blue\": (30,30,220)}\n",
        "    shapes = [\"circle\",\"square\",\"triangle\"]\n",
        "    items = []\n",
        "    for s in shapes:\n",
        "        for name,c in colors.items():\n",
        "            img = make_shape_image(s, c)\n",
        "            text = f\"{name} {s}\"\n",
        "            items.append((img, text))\n",
        "    random.shuffle(items)\n",
        "    # Train/test split with compositional holdout (e.g., blue triangle held out)\n",
        "    test_holdouts = {\"blue triangle\", \"green circle\"}\n",
        "    train = [(img, txt) for img,txt in items if txt not in test_holdouts]\n",
        "    test = [(img, txt) for img,txt in items if txt in test_holdouts]\n",
        "    return train, test\n",
        "\n",
        "def run_multimodal_episode(agent: AgentAdapter, pool: list[tuple[np.ndarray,str]], q: tuple[str|np.ndarray, list], mode=\"txt2img\", split=\"train\") -> EpisodeResult:\n",
        "    if mode == \"txt2img\":\n",
        "        text = q[0]; images = q[1]\n",
        "        pred_idx, _, _ = agent.act({\"mode\": \"txt2img\", \"text\": text, \"images\": images}, task_id=\"multimodal/match\", step=0, state=None)\n",
        "        # success if chosen image corresponds to text\n",
        "        success = int(any(text == t for (im,t) in pool if (im.tobytes() == images[pred_idx].tobytes())))\n",
        "    else:\n",
        "        image = q[0]; texts = q[1]\n",
        "        pred_idx, _, _ = agent.act({\"mode\": \"img2txt\", \"image\": image, \"texts\": texts}, task_id=\"multimodal/match\", step=0, state=None)\n",
        "        # success if chosen text corresponds to image\n",
        "        success = int(any(texts[pred_idx] == t for (im,t) in pool if (im.tobytes() == image.tobytes())))\n",
        "    return EpisodeResult(\"multimodal/match\", split, success, 1, float(success), meta={\"mode\": mode})\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 3. Evaluation protocols and metrics\n",
        "# - Forward transfer: pretrain on some tasks; measure zero/low-shot on new tasks\n",
        "# - Compositional generalization: held-out combos in symbol/multimodal; larger grids with keys\n",
        "# - Epistemic uncertainty: MC dropout predictive variance (regression)\n",
        "# - Reflective improvement: performance delta after reflect()\n",
        "\n",
        "# %%\n",
        "@dataclass\n",
        "class EvalConfig:\n",
        "    n_symbol_train: int = 20\n",
        "    n_symbol_test: int = 10\n",
        "    n_grid_train: int = 20\n",
        "    n_grid_test: int = 10\n",
        "    n_reg_train: int = 20\n",
        "    n_reg_test: int = 10\n",
        "    k_shot: int = 10\n",
        "    q_points: int = 50\n",
        "    mm_trials: int = 20\n",
        "\n",
        "def mc_dropout_uncertainty(agent: SimpleAgentAdapter, x: np.ndarray, n_passes: int) -> float:\n",
        "    if not TORCH_AVAILABLE or agent.reg_model is None:\n",
        "        return float(\"nan\")\n",
        "    agent.reg_model.train(True)  # enable dropout\n",
        "    preds = []\n",
        "    with torch.no_grad():\n",
        "        xt = torch.from_numpy(x).float().to(DEVICE)\n",
        "        for _ in range(n_passes):\n",
        "            preds.append(agent.reg_model(xt).cpu().numpy())\n",
        "    P = np.stack(preds, axis=0)  # [passes, B, 1]\n",
        "    var = float(np.mean(np.var(P, axis=0)))\n",
        "    agent.reg_model.train(True)\n",
        "    return var\n",
        "\n",
        "# %% [markdown]\n",
        "# ## 4. Orchestrator\n",
        "\n",
        "# %%\n",
        "def run_all(agent: AgentAdapter, eval_cfg=EvalConfig(), run_id=RUN_ID):\n",
        "    records = []\n",
        "\n",
        "    # --- SYMBOL ---\n",
        "    sym_train, sym_test = generate_symbol_dataset(SEED)\n",
        "    for task in sym_train[:eval_cfg.n_symbol_train]:\n",
        "        res = run_symbol_episode(agent, task, split=\"train\")\n",
        "        records.append(dataclasses.asdict(res) | {\"run_id\": run_id})\n",
        "    for task in sym_test[:eval_cfg.n_symbol_test]:\n",
        "        res = run_symbol_episode(agent, task, split=\"test\")\n",
        "        records.append(dataclasses.asdict(res) | {\"run_id\": run_id})\n",
        "\n",
        "    # --- GRID ---\n",
        "    grid_train, grid_test = generate_grid_dataset(SEED)\n",
        "    for task in grid_train[:eval_cfg.n_grid_train]:\n",
        "        res = run_grid_episode(agent, task, split=\"train\")\n",
        "        records.append(dataclasses.asdict(res) | {\"run_id\": run_id})\n",
        "    for task in grid_test[:eval_cfg.n_grid_test]:\n",
        "        res = run_grid_episode(agent, task, split=\"test\")\n",
        "        records.append(dataclasses.asdict(res) | {\"run_id\": run_id})\n",
        "\n",
        "    # --- REGRESSION (Forward transfer proxy: measure pre/post on test without training on that task) ---\n",
        "sin_train, sin_test = generate_sin_tasks(SEED)\n",
        "# Pretrain a bit across train tasks\n",
        "for task in sin_train[:eval_cfg.n_reg_train]:\n",
        "    r = run_regression_episode(agent, task, k_shot=eval_cfg.k_shot, q_points=eval_cfg.q_points, split=\"train\")\n",
        "    records.append(dataclasses.asdict(r) | {\"run_id\": run_id})\n",
        "# Evaluate on unseen tasks with minimal adaptation\n",
        "for task in sin_test[:eval_cfg.n_reg_test]:\n",
        "    r = run_regression_episode(agent, task, k_shot=eval_cfg.k_shot // 2, q_points=eval_cfg.q_points, split=\"test\")\n",
        "    records.append(dataclasses.asdict(r) | {\"run_id\": run_id})\n",
        "    # Epistemic uncertainty\n",
        "    xq, _ = sample_sin_task(64, task)\n",
        "    if isinstance(agent, SimpleAgentAdapter):\n",
        "        unc = mc_dropout_uncertainty(agent, xq, n_passes=agent.cfg.mc_dropout_passes)\n",
        "    else:\n",
        "        unc = float(\"nan\")\n",
        "    records[-1][\"meta\"][\"epistemic_var\"] = unc\n",
        "\n",
        "def run_all(agent):\n",
        "    records = []\n",
        "    run_id = RUN_ID  # or however you define it earlier\n",
        "\n",
        "    # --- MULTIMODAL (Compositional holdout) ---\n",
        "    mm_train, mm_test = generate_multimodal_dataset(SEED)\n",
        "\n",
        "    # txt->img (train)\n",
        "    for _ in range(eval_cfg.mm_trials):\n",
        "        text = random.choice([t for (_, t) in mm_train])\n",
        "        imgs = [im for (im, _) in random.sample(mm_train, k=min(4, len(mm_train)))]\n",
        "        r = run_multimodal_episode(agent, mm_train, (text, imgs), mode=\"txt2img\", split=\"train\")\n",
        "        records.append(dataclasses.asdict(r) | {\"run_id\": run_id})\n",
        "\n",
        "    # img->txt (held-out compositions in test)\n",
        "    for _ in range(max(5, eval_cfg.mm_trials // 2)):\n",
        "        if not mm_test:\n",
        "            break\n",
        "        im, t_hold = random.choice(mm_test)\n",
        "        candidates = [t_hold] + [t for (_, t) in random.sample(mm_train, k=min(3, len(mm_train)))]\n",
        "        random.shuffle(candidates)\n",
        "        r = run_multimodal_episode(agent, mm_train + mm_test, (im, candidates), mode=\"img2txt\", split=\"test\")\n",
        "        records.append(dataclasses.asdict(r) | {\"run_id\": run_id})\n",
        "\n",
        "    # --- Reflection cycle ---\n",
        "    refl_notes = agent.reflect(records)\n",
        "    print(\"Reflection:\", refl_notes)\n",
        "\n",
        "    # Recreate the test splits so they're available here\n",
        "    sym_train, sym_test = generate_symbol_dataset(SEED)\n",
        "    grid_train, grid_test = generate_grid_dataset(SEED)\n",
        "    sin_train, sin_test = generate_sin_tasks(SEED)\n",
        "\n",
        "    # Slim post‑reflect pass\n",
        "    sym_r = run_symbol_episode(agent, sym_test[0], split=\"post-reflect\")\n",
        "    grid_r = run_grid_episode(agent, grid_test[0], split=\"post-reflect\")\n",
        "    sin_r = run_regression_episode(\n",
        "        agent,\n",
        "        sin_test[0],\n",
        "        k_shot=eval_cfg.k_shot // 2,\n",
        "        q_points=eval_cfg.q_points,\n",
        "        split=\"post-reflect\"\n",
        "    )\n",
        "    records += [\n",
        "        dataclasses.asdict(sym_r) | {\"run_id\": run_id},\n",
        "        dataclasses.asdict(grid_r) | {\"run_id\": run_id},\n",
        "        dataclasses.asdict(sin_r) | {\"run_id\": run_id},\n",
        "    ]\n",
        "\n",
        "    # Persist\n",
        "    out_path = f\"runs/{run_id}.jsonl\"\n",
        "    for rec in records:\n",
        "        log_jsonl(out_path, rec)\n",
        "\n",
        "    # ✅ Return everything you need for the dashboard and post‑reflect analysis\n",
        "    return pd.DataFrame.from_records(records), refl_notes, sym_test, grid_test, sin_test\n",
        "\n",
        "# %% [markdown]\n",
        "# 5. Dashboard\n",
        "\n",
        "# %%\n",
        "def dashboard(df: pd.DataFrame):\n",
        "    # Summary by task/split\n",
        "    df[\"success\"] = df[\"success\"].astype(int)\n",
        "    agg = df.groupby([\"task_id\", \"split\"]).agg(\n",
        "        success_rate=(\"success\", \"mean\"),\n",
        "        avg_reward=(\"reward\", \"mean\"),\n",
        "        avg_steps=(\"steps\", \"mean\"),\n",
        "        n=(\"success\", \"count\"),\n",
        "    ).reset_index()\n",
        "    display(agg)\n",
        "\n",
        "    # Plot success rates\n",
        "    pivot = agg.pivot(index=\"task_id\", columns=\"split\", values=\"success_rate\").fillna(0.0)\n",
        "    pivot.plot(kind=\"bar\", figsize=(10, 4), ylim=(0, 1), title=\"Success rate by task and split\")\n",
        "    plt.axhline(0.5, color=\"gray\", linestyle=\"--\", linewidth=1)\n",
        "    plt.show()\n",
        "\n",
        "    # Regression pre/post MSE distribution\n",
        "    reg = df[df[\"task_id\"] == \"regress/sin\"].copy()\n",
        "    if not reg.empty:\n",
        "        pre = [m.get(\"pre_mse\") for m in reg[\"meta\"] if isinstance(m, dict) and \"pre_mse\" in m]\n",
        "        post = [m.get(\"post_mse\") for m in reg[\"meta\"] if isinstance(m, dict) and \"post_mse\" in m]\n",
        "        if pre and post:\n",
        "            plt.figure(figsize=(6, 4))\n",
        "            plt.hist(pre, bins=15, alpha=0.6, label=\"pre\")\n",
        "            plt.hist(post, bins=15, alpha=0.6, label=\"post\")\n",
        "            plt.title(\"Regression MSE pre vs post adaptation\")\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "\n",
        "    # Epistemic variance on test (sin tasks)\n",
        "    ev = [\n",
        "        m.get(\"epistemic_var\")\n",
        "        for m in df[df[\"split\"] == \"test\"][\"meta\"]\n",
        "        if isinstance(m, dict) and \"epistemic_var\" in m\n",
        "    ]\n",
        "    if ev:\n",
        "        plt.figure(figsize=(6, 3))\n",
        "        plt.plot(ev, marker=\"o\")\n",
        "        plt.title(\"Epistemic variance across unseen sin tasks\")\n",
        "        plt.show()\n",
        "\n",
        "# %% [markdown]\n",
        "# 6. Run — using the provided SimpleAgentAdapter\n",
        "\n",
        "# %%\n",
        "cfg = AgentConfig(\n",
        "    name=\"SimpleAgent\",\n",
        "    use_world_model=False,\n",
        "    use_multimodal_encoder=True,\n",
        "    notes=\"baseline\"\n",
        ")\n",
        "\n",
        "agent = SimpleAgentAdapter(cfg)  # <-- your real adapter class\n",
        "df, refl_notes, sym_test, grid_test, sin_test = run_all(agent)\n",
        "dashboard(df)\n",
        "print(\"Run complete:\", RUN_ID)\n",
        "\n",
        "\n",
        "# %% [markdown]\n",
        "# ---\n",
        "# 7. Integration hooks for your AGI agent\n",
        "#\n",
        "# If you have your own AGI scaffold (with memory, planner, reflector, etc.),\n",
        "# wrap it in an adapter like this. Only run this block once `MyAGIAgent` exists.\n",
        "\n",
        "# %%\n",
        "class MyAGIAgentAdapter(AgentAdapter):\n",
        "    def __init__(self, cfg: AgentConfig):\n",
        "        super().__init__(cfg)\n",
        "        # Instantiate your full AGI scaffold here\n",
        "        self.agent = MyAGIAgent(\n",
        "            # pass in any required modules/configs for your scaffold\n",
        "            memory_module=...,\n",
        "            planner_module=...,\n",
        "            reflector_module=...,\n",
        "            world_model=...,\n",
        "            multimodal_encoder=...\n",
        "        )\n",
        "\n",
        "    def act(self, obs, task_id, step, state):\n",
        "        return self.agent.act(obs, task_id, step, state)\n",
        "\n",
        "    def learn(self, batch, task_id):\n",
        "        return self.agent.learn(batch, task_id)\n",
        "\n",
        "    def reflect(self, logs):\n",
        "        return self.agent.reflect(logs)\n",
        "\n",
        "    def encode(self, modality, data):\n",
        "        return self.agent.encode(modality, data)\n",
        "\n",
        "    def imagine(self, state, n_steps=5):\n",
        "        return self.agent.world_model.rollout(state, n_steps)\n",
        "\n",
        "\n",
        "# Example usage — only if MyAGIAgent is implemented:\n",
        "# cfg = AgentConfig(\n",
        "#     name=\"MyAGIAgent\",\n",
        "#     use_world_model=True,\n",
        "#     use_multimodal_encoder=True,\n",
        "#     notes=\"full AGI scaffold\"\n",
        "# )\n",
        "# agent = MyAGIAgentAdapter(cfg)\n",
        "# df, refl_notes, sym_test, grid_test, sin_test = run_all(agent)\n",
        "# dashboard(df)"
      ]
    }
  ]
}