{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyN6O2Sprmb9R2ORem/ANnFW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Pinn/blob/main/SecureAGISystem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrLRpG-VH4ss"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import yaml\n",
        "import hashlib\n",
        "import logging\n",
        "from datetime import datetime\n",
        "from typing import Optional, Tuple, Dict, Any\n",
        "from cryptography.fernet import Fernet\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from tensorflow.distribute import MultiWorkerMirroredStrategy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import boto3\n",
        "\n",
        "# --- Custom Exceptions ---\n",
        "class ModelInitializationError(Exception): pass\n",
        "class ModelNotFoundError(Exception): pass\n",
        "\n",
        "class SecureAGISystem:\n",
        "    def __init__(self, config_path: str, model_loader, distributed_training: bool = False, encryption_key: Optional[bytes] = None):\n",
        "        self.config = self._load_config(config_path)\n",
        "        self.models: Dict[str, Model] = {}\n",
        "        self.model_loader = model_loader\n",
        "        self.distributed_training = distributed_training\n",
        "        self.strategy = self._initialize_strategy()\n",
        "        self.encryption_key = encryption_key\n",
        "        self.fernet = Fernet(encryption_key) if encryption_key else None\n",
        "\n",
        "        os.makedirs(\"models\", exist_ok=True)\n",
        "        os.makedirs(\"logs\", exist_ok=True)\n",
        "        os.makedirs(\"reports\", exist_ok=True)\n",
        "        os.makedirs(\"checkpoints\", exist_ok=True)\n",
        "\n",
        "        logging.basicConfig(filename=\"training_audit.log\", level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "        logging.info(\"SecureAGISystem initialized.\")\n",
        "\n",
        "    def _load_config(self, path: str) -> Dict[str, Any]:\n",
        "        with open(path, 'r') as f:\n",
        "            return yaml.safe_load(f) if path.endswith(\".yaml\") else json.load(f)\n",
        "\n",
        "    def _initialize_strategy(self):\n",
        "        if self.distributed_training:\n",
        "            return MultiWorkerMirroredStrategy()\n",
        "        return None\n",
        "\n",
        "    def _compute_dataset_hash(self, data: np.ndarray) -> str:\n",
        "        return hashlib.sha256(data.tobytes()).hexdigest()\n",
        "\n",
        "    def validate_dataset(self, x_train, y_train, expected_hash: Optional[str] = None):\n",
        "        current_hash = self._compute_dataset_hash(x_train) + self._compute_dataset_hash(y_train)\n",
        "        if expected_hash and current_hash != expected_hash:\n",
        "            raise ValueError(\"Dataset integrity check failed!\")\n",
        "        return current_hash\n",
        "\n",
        "    def get_model(self, model_name: str) -> Model:\n",
        "        if model_name in self.models:\n",
        "            return self.models[model_name]\n",
        "        model = self.model_loader(model_name)\n",
        "        if not isinstance(model, Model):\n",
        "            raise ModelNotFoundError(f\"No valid model for '{model_name}'\")\n",
        "        self.models[model_name] = model\n",
        "        return model\n",
        "\n",
        "    def save_model(self, model: Model, model_name: str, metrics: Dict[str, Any]):\n",
        "        version = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "        save_path = os.path.join(\"models\", model_name, version)\n",
        "        os.makedirs(save_path, exist_ok=True)\n",
        "        model.save(save_path)\n",
        "\n",
        "        if self.fernet:\n",
        "            for file in os.listdir(save_path):\n",
        "                file_path = os.path.join(save_path, file)\n",
        "                with open(file_path, 'rb') as f:\n",
        "                    encrypted = self.fernet.encrypt(f.read())\n",
        "                with open(file_path, 'wb') as f:\n",
        "                    f.write(encrypted)\n",
        "\n",
        "        metadata = {\"model_name\": model_name, \"version\": version, \"metrics\": metrics}\n",
        "        with open(os.path.join(save_path, \"metadata.json\"), \"w\") as f:\n",
        "            json.dump(metadata, f)\n",
        "\n",
        "        logging.info(f\"Model saved: {metadata}\")\n",
        "        return save_path, version\n",
        "\n",
        "    def generate_training_report(self, history, metadata, save_path):\n",
        "        plt.figure(figsize=(10,5))\n",
        "        for key in history.history:\n",
        "            plt.plot(history.history[key], label=key)\n",
        "        plt.legend()\n",
        "        plt.title(\"Training Metrics\")\n",
        "        plt.xlabel(\"Epoch\")\n",
        "        plt.ylabel(\"Value\")\n",
        "        plot_path = save_path.replace(\".html\", \"_plot.png\")\n",
        "        plt.savefig(plot_path)\n",
        "        plt.close()\n",
        "\n",
        "        html_content = f\"\"\"\n",
        "        <html>\n",
        "        <head><title>Training Report</title></head>\n",
        "        <body>\n",
        "            <h1>Model Training Report</h1>\n",
        "            <h2>Metadata</h2>\n",
        "            <pre>{json.dumps(metadata, indent=4)}</pre>\n",
        "            <h2>Training Curves</h2>\n",
        "            <img src=\"{os.path.basename(plot_path)}\" alt=\"Training Plot\">\n",
        "        </body>\n",
        "        </html>\n",
        "        \"\"\"\n",
        "        with open(save_path, \"w\") as f:\n",
        "            f.write(html_content)\n",
        "\n",
        "    def upload_to_s3(self, local_path, bucket_name, s3_path):\n",
        "        s3 = boto3.client(\"s3\")\n",
        "        for root, dirs, files in os.walk(local_path):\n",
        "            for file in files:\n",
        "                full_path = os.path.join(root, file)\n",
        "                rel_path = os.path.relpath(full_path, local_path)\n",
        "                s3.upload_file(full_path, bucket_name, os.path.join(s3_path, rel_path))\n",
        "\n",
        "    def train(self, model_name: str, data: Tuple[np.ndarray, np.ndarray], val_data: Optional[Tuple[np.ndarray, np.ndarray]] = None):\n",
        "        cfg = self.config[\"training\"]\n",
        "\n",
        "        dataset_hash = self.validate_dataset(data[0], data[1], self.config.get(\"expected_dataset_hash\"))\n",
        "\n",
        "        log_dir = os.path.join(\"logs\", \"fit\", f\"{model_name}_{datetime.now().strftime('%Y%m%d-%H%M%S')}\")\n",
        "        callbacks = [\n",
        "            TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
        "            ModelCheckpoint(filepath=f\"checkpoints/{model_name}.h5\", save_best_only=True)\n",
        "        ]\n",
        "\n",
        "        if self.strategy:\n",
        "            with self.strategy.scope():\n",
        "                model = self.get_model(model_name)\n",
        "                model.compile(optimizer=cfg[\"optimizer\"], loss=cfg[\"loss\"], metrics=cfg[\"metrics\"])\n",
        "        else:\n",
        "            model = self.get_model(model_name)\n",
        "            model.compile(optimizer=cfg[\"optimizer\"], loss=cfg[\"loss\"], metrics=cfg[\"metrics\"])\n",
        "\n",
        "        history = model.fit(\n",
        "            data[0], data[1],\n",
        "            epochs=cfg[\"epochs\"],\n",
        "            batch_size=cfg[\"batch_size\"],\n",
        "            validation_data=val_data,\n",
        "            callbacks=callbacks\n",
        "        )\n",
        "\n",
        "        final_metrics = {m: history.history[m][-1] for m in history.history}\n",
        "        save_path, version = self.save_model(model, model_name, final_metrics)\n",
        "\n",
        "        metadata = {\"model_name\": model_name, \"dataset_hash\": dataset_hash, \"final_metrics\": final_metrics, \"version\": version}\n",
        "        report_path = f\"reports/{model_name}_{version}.html\"\n",
        "        self.generate_training_report(history, metadata, report_path)\n",
        "\n",
        "        if self.config.get(\"cloud_upload\"):\n",
        "            self.upload_to_s3(save_path, self.config[\"s3_bucket\"], f\"{model_name}/{version}\")"
      ]
    }
  ]
}