{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNBEPQmP2B0FlU77bYLHcSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Pinn/blob/main/train_multihop_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZVdB7M6-NCIt"
      },
      "outputs": [],
      "source": [
        "# train_multihop.py\n",
        "import argparse\n",
        "import math\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from multihop_reasoner import MultiHopReasoner, set_seed\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def generate_batch(\n",
        "    true_facts: torch.Tensor,         # (N, D)\n",
        "    true_relations: torch.Tensor,     # (R, D, D)\n",
        "    hops: int,\n",
        "    batch_size: int,\n",
        "    noise_std: float = 0.0,\n",
        "    device: str = \"cpu\",\n",
        "):\n",
        "    \"\"\"\n",
        "    Sample batch of (query, target_fact_index) pairs:\n",
        "      - Choose target index t\n",
        "      - Choose a chain of relations r_1..r_K\n",
        "      - Query = facts[t] @ R_{r1} @ ... @ R_{rK} + noise\n",
        "    \"\"\"\n",
        "    N, D = true_facts.shape\n",
        "    R = true_relations.size(0)\n",
        "\n",
        "    t_idx = torch.randint(low=0, high=N, size=(batch_size,), device=device)  # (B,)\n",
        "    # Sample relation chains\n",
        "    r_chain = torch.randint(low=0, high=R, size=(batch_size, hops), device=device)  # (B, K)\n",
        "\n",
        "    # Build queries\n",
        "    q = torch.zeros(batch_size, D, device=device)\n",
        "    for b in range(batch_size):\n",
        "        v = true_facts[t_idx[b]]  # (D,)\n",
        "        # Apply chain\n",
        "        for k in range(hops):\n",
        "            r = r_chain[b, k]\n",
        "            v = v @ true_relations[r]  # (D,)\n",
        "        q[b] = v\n",
        "\n",
        "    if noise_std > 0:\n",
        "        q = q + noise_std * torch.randn_like(q)\n",
        "\n",
        "    # Normalize queries (optional, matches cosine-based scoring)\n",
        "    q = q / (q.norm(dim=-1, keepdim=True) + 1e-8)\n",
        "\n",
        "    return q, t_idx\n",
        "\n",
        "\n",
        "def train(\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    num_facts=64,\n",
        "    embedding_dim=64,\n",
        "    num_relations=4,\n",
        "    hops=2,\n",
        "    batch_size=128,\n",
        "    steps=5000,\n",
        "    lr=3e-4,\n",
        "    noise_std=0.0,\n",
        "    seed=42,\n",
        "    log_every=100,\n",
        "):\n",
        "    set_seed(seed)\n",
        "\n",
        "    # Hidden ground-truth world to generate supervision\n",
        "    true_facts = torch.randn(num_facts, embedding_dim, device=device)\n",
        "    true_facts = true_facts / (true_facts.norm(dim=-1, keepdim=True) + 1e-8)\n",
        "    true_relations = torch.empty(num_relations, embedding_dim, embedding_dim, device=device)\n",
        "    nn.init.orthogonal_(true_relations)  # helpful for stable chaining\n",
        "\n",
        "    # Model (can choose to train facts or treat them as a separate memory)\n",
        "    model = MultiHopReasoner(\n",
        "        num_facts=num_facts,\n",
        "        embedding_dim=embedding_dim,\n",
        "        num_relations=num_relations,\n",
        "        hops=hops,\n",
        "        temperature=0.2,\n",
        "        train_facts=True,\n",
        "        layer_norm=True,\n",
        "        dropout_p=0.0,\n",
        "    ).to(device)\n",
        "\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for step in range(1, steps + 1):\n",
        "        model.train()\n",
        "        q, targets = generate_batch(true_facts, true_relations, hops, batch_size, noise_std, device)\n",
        "\n",
        "        probs, extras = model(q, return_intermediates=True)\n",
        "        loss = F.nll_loss((probs + 1e-8).log(), targets)\n",
        "\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)\n",
        "        opt.step()\n",
        "\n",
        "        if step % log_every == 0 or step == 1:\n",
        "            with torch.no_grad():\n",
        "                preds = probs.argmax(dim=-1)\n",
        "                acc = (preds == targets).float().mean().item()\n",
        "            best_acc = max(best_acc, acc)\n",
        "            # Inspect latest hop relation weights (mean over batch)\n",
        "            rel_mean = torch.stack(extras[\"rel_weights\"])[-1].mean(dim=0)  # (R,)\n",
        "            print(\n",
        "                f\"[{step:05d}] loss={loss.item():.4f} acc={acc:.3f} best={best_acc:.3f} \"\n",
        "                f\"rel_w={rel_mean.cpu().numpy()}\"\n",
        "            )\n",
        "\n",
        "    # Quick qualitative check\n",
        "    with torch.no_grad():\n",
        "        q, targets = generate_batch(true_facts, true_relations, hops, batch_size=4, noise_std=noise_std, device=device)\n",
        "        probs, extras = model(q, return_intermediates=True)\n",
        "        preds = probs.argmax(dim=-1)\n",
        "        print(\"\\nSample predictions:\")\n",
        "        for i in range(q.size(0)):\n",
        "            print(f\"target={targets[i].item():3d} pred={preds[i].item():3d} top5={probs[i].topk(5).indices.tolist()}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import argparse\n",
        "\n",
        "    p = argparse.ArgumentParser(description=\"Train a multi-hop symbolic reasoner on synthetic chained-relations.\")\n",
        "    p.add_argument(\"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    p.add_argument(\"--num-facts\", type=int, default=64)\n",
        "    p.add_argument(\"--embedding-dim\", type=int, default=64)\n",
        "    p.add_argument(\"--num-relations\", type=int, default=4)\n",
        "    p.add_argument(\"--hops\", type=int, default=2)\n",
        "    p.add_argument(\"--batch-size\", type=int, default=128)\n",
        "    p.add_argument(\"--steps\", type=int, default=5000)\n",
        "    p.add_argument(\"--lr\", type=float, default=3e-4)\n",
        "    p.add_argument(\"--noise-std\", type=float, default=0.0)\n",
        "    p.add_argument(\"--seed\", type=int, default=42)\n",
        "    p.add_argument(\"--log-every\", type=int, default=100)\n",
        "    args = p.parse_args()\n",
        "\n",
        "    train(\n",
        "        device=args.device,\n",
        "        num_facts=args.num_facts,\n",
        "        embedding_dim=args.embedding_dim,\n",
        "        num_relations=args.num_relations,\n",
        "        hops=args.hops,\n",
        "        batch_size=args.batch_size,\n",
        "        steps=args.steps,\n",
        "        lr=args.lr,\n",
        "        noise_std=args.noise_std,\n",
        "        seed=args.seed,\n",
        "        log_every=args.log_every,\n",
        "    )"
      ]
    }
  ]
}