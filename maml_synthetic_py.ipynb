{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNeyk/uQpG2jsecqWBK/7Rq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Pinn/blob/main/maml_synthetic_py.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpaEHSIGHfsD"
      },
      "outputs": [],
      "source": [
        "# maml_synthetic.py\n",
        "# Minimal, reproducible MAML training on synthetic N-way K-shot Gaussian classification.\n",
        "# - Gaussian task sampler (new task each episode)\n",
        "# - Higher- or first-order MAML\n",
        "# - Meta-train/val loop with accuracy and checkpointing\n",
        "# - Deterministic seeding and safe defaults\n",
        "\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import argparse\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Utilities\n",
        "# ---------------------------\n",
        "\n",
        "def set_seed(seed: int = 42, deterministic: bool = True):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    if deterministic:\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "def accuracy_from_logits(logits: torch.Tensor, targets: torch.Tensor) -> float:\n",
        "    preds = logits.argmax(dim=-1)\n",
        "    return (preds == targets).float().mean().item()\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Model: functional forward\n",
        "# ---------------------------\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, in_dim=2, hidden=40, out_dim=2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, hidden), nn.ReLU(),\n",
        "            nn.Linear(hidden, out_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "    def forward_with_weights(self, x, weights: \"OrderedDict[str, torch.Tensor]\"):\n",
        "        # Mirror nn.Sequential: Linear -> ReLU -> Linear\n",
        "        x = F.linear(x, weights['net.0.weight'], weights['net.0.bias'])\n",
        "        x = F.relu(x)\n",
        "        x = F.linear(x, weights['net.2.weight'], weights['net.2.bias'])\n",
        "        return x\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# MAML meta-learner\n",
        "# ---------------------------\n",
        "\n",
        "class MAML(nn.Module):\n",
        "    def __init__(self, model: nn.Module, lr_inner: float = 0.01, first_order: bool = False):\n",
        "        super().__init__()\n",
        "        self.model = model\n",
        "        self.lr_inner = lr_inner\n",
        "        self.first_order = first_order\n",
        "\n",
        "    def adapt(self, support_x, support_y, n_inner_steps: int, create_graph: bool):\n",
        "        # Start from current meta-parameters\n",
        "        fast_weights = OrderedDict(self.model.named_parameters())\n",
        "\n",
        "        for _ in range(n_inner_steps):\n",
        "            y_pred = self.model.forward_with_weights(support_x, fast_weights)\n",
        "            loss = F.cross_entropy(y_pred, support_y)\n",
        "            grads = torch.autograd.grad(\n",
        "                loss,\n",
        "                fast_weights.values(),\n",
        "                create_graph=create_graph,  # second-order if True\n",
        "                retain_graph=create_graph\n",
        "            )\n",
        "            fast_weights = OrderedDict(\n",
        "                (name, param - self.lr_inner * g)\n",
        "                for (name, param), g in zip(fast_weights.items(), grads)\n",
        "            )\n",
        "        return fast_weights\n",
        "\n",
        "    def forward(self, task_data, n_inner_steps: int = 1, create_graph: bool = None):\n",
        "        if create_graph is None:\n",
        "            create_graph = not self.first_order\n",
        "\n",
        "        query_losses = []\n",
        "        query_accs = []\n",
        "\n",
        "        for support_x, support_y, query_x, query_y in task_data:\n",
        "            fast_weights = self.adapt(support_x, support_y, n_inner_steps, create_graph=create_graph)\n",
        "            query_logits = self.model.forward_with_weights(query_x, fast_weights)\n",
        "            q_loss = F.cross_entropy(query_logits, query_y)\n",
        "            query_losses.append(q_loss)\n",
        "            query_accs.append(accuracy_from_logits(query_logits, query_y))\n",
        "\n",
        "        meta_loss = torch.stack(query_losses).mean()\n",
        "        meta_acc = float(sum(query_accs) / len(query_accs))\n",
        "        return meta_loss, meta_acc\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Synthetic task sampler\n",
        "# ---------------------------\n",
        "\n",
        "class GaussianNWayKShot:\n",
        "    \"\"\"\n",
        "    N-way K-shot tasks in R^in_dim:\n",
        "    - Each class ~ N(mu_c, sigma^2 I)\n",
        "    - For each task, sample class centers and scales\n",
        "    - Return (support_x, support_y, query_x, query_y)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_way: int,\n",
        "        k_shot: int,\n",
        "        q_queries: int,\n",
        "        in_dim: int = 2,\n",
        "        radius: float = 5.0,\n",
        "        scale_range=(0.6, 1.2),\n",
        "        device: str = \"cpu\",\n",
        "        seed: int = 1234\n",
        "    ):\n",
        "        self.n_way = n_way\n",
        "        self.k_shot = k_shot\n",
        "        self.q_queries = q_queries\n",
        "        self.in_dim = in_dim\n",
        "        self.radius = radius\n",
        "        self.scale_range = scale_range\n",
        "        self.device = device\n",
        "        self._g = torch.Generator(device=\"cpu\").manual_seed(seed)\n",
        "\n",
        "    def _sample_centers(self):\n",
        "        # Sample class centers on a ring (more separable) with jitter\n",
        "        angles = torch.rand(self.n_way, generator=self._g) * 2 * math.pi\n",
        "        base = torch.stack([torch.cos(angles), torch.sin(angles)], dim=1)  # (n_way, 2)\n",
        "        if self.in_dim > 2:\n",
        "            pad = torch.zeros(self.n_way, self.in_dim - 2)\n",
        "            centers = torch.cat([base, pad], dim=1)\n",
        "        else:\n",
        "            centers = base[:, :self.in_dim]\n",
        "        centers = centers * self.radius\n",
        "        # Add small jitter\n",
        "        centers = centers + 0.2 * torch.randn_like(centers, generator=self._g)\n",
        "        return centers\n",
        "\n",
        "    def _sample_sigma(self):\n",
        "        low, high = self.scale_range\n",
        "        return low + (high - low) * torch.rand(self.n_way, generator=self._g)\n",
        "\n",
        "    def sample_task(self):\n",
        "        centers = self._sample_centers()  # (n_way, in_dim)\n",
        "        sigmas = self._sample_sigma()     # (n_way,)\n",
        "\n",
        "        n_support = self.k_shot\n",
        "        n_query = self.q_queries\n",
        "\n",
        "        xs_support = []\n",
        "        ys_support = []\n",
        "        xs_query = []\n",
        "        ys_query = []\n",
        "\n",
        "        for c in range(self.n_way):\n",
        "            mu = centers[c]\n",
        "            sigma = sigmas[c]\n",
        "            total = n_support + n_query\n",
        "            pts = mu + sigma * torch.randn(total, self.in_dim, generator=self._g)\n",
        "            xs_support.append(pts[:n_support])\n",
        "            xs_query.append(pts[n_support:])\n",
        "            ys_support.append(torch.full((n_support,), c, dtype=torch.long))\n",
        "            ys_query.append(torch.full((n_query,), c, dtype=torch.long))\n",
        "\n",
        "        support_x = torch.cat(xs_support, dim=0).to(self.device)\n",
        "        support_y = torch.cat(ys_support, dim=0).to(self.device)\n",
        "        query_x = torch.cat(xs_query, dim=0).to(self.device)\n",
        "        query_y = torch.cat(ys_query, dim=0).to(self.device)\n",
        "\n",
        "        # Shuffle within support and query for good measure\n",
        "        def _shuffle(x, y):\n",
        "            idx = torch.randperm(x.size(0), generator=self._g)\n",
        "            return x[idx].to(self.device), y[idx].to(self.device)\n",
        "\n",
        "        support_x, support_y = _shuffle(support_x, support_y)\n",
        "        query_x, query_y = _shuffle(query_x, query_y)\n",
        "\n",
        "        return support_x, support_y, query_x, query_y\n",
        "\n",
        "    def sample_meta_batch(self, batch_size: int):\n",
        "        return [self.sample_task() for _ in range(batch_size)]\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# Training and evaluation\n",
        "# ---------------------------\n",
        "\n",
        "def train_maml(\n",
        "    n_way=3,\n",
        "    k_shot=5,\n",
        "    q_queries=15,\n",
        "    in_dim=2,\n",
        "    inner_steps=5,\n",
        "    inner_lr=0.4,\n",
        "    first_order=False,\n",
        "    outer_lr=1e-3,\n",
        "    meta_batch=16,\n",
        "    epochs=3000,\n",
        "    val_every=50,\n",
        "    seed=42,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    checkpoint_path=\"./checkpoints/maml_synthetic.pt\",\n",
        "):\n",
        "    set_seed(seed, deterministic=True)\n",
        "    os.makedirs(os.path.dirname(checkpoint_path), exist_ok=True)\n",
        "\n",
        "    # Build components\n",
        "    model = SimpleNet(in_dim=in_dim, hidden=40, out_dim=n_way).to(device)\n",
        "    maml = MAML(model, lr_inner=inner_lr, first_order=first_order).to(device)\n",
        "    outer_opt = optim.Adam(maml.parameters(), lr=outer_lr)\n",
        "\n",
        "    # Task samplers (distinct RNG seeds)\n",
        "    train_sampler = GaussianNWayKShot(\n",
        "        n_way=n_way, k_shot=k_shot, q_queries=q_queries,\n",
        "        in_dim=in_dim, radius=5.0, scale_range=(0.6, 1.2),\n",
        "        device=device, seed=seed + 1\n",
        "    )\n",
        "    val_sampler = GaussianNWayKShot(\n",
        "        n_way=n_way, k_shot=k_shot, q_queries=q_queries,\n",
        "        in_dim=in_dim, radius=5.0, scale_range=(0.6, 1.2),\n",
        "        device=device, seed=seed + 999\n",
        "    )\n",
        "\n",
        "    best_val_acc = 0.0\n",
        "    ema_loss = None\n",
        "\n",
        "    t0 = time.time()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        maml.train()\n",
        "        task_batch = train_sampler.sample_meta_batch(meta_batch)\n",
        "        outer_opt.zero_grad()\n",
        "\n",
        "        meta_loss, meta_acc = maml(task_batch, n_inner_steps=inner_steps, create_graph=not first_order)\n",
        "        meta_loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(maml.parameters(), max_norm=5.0)\n",
        "        outer_opt.step()\n",
        "\n",
        "        # Smooth loss for readability\n",
        "        ema_loss = meta_loss.item() if ema_loss is None else 0.9 * ema_loss + 0.1 * meta_loss.item()\n",
        "\n",
        "        if epoch % val_every == 0 or epoch == 1:\n",
        "            maml.eval()\n",
        "            with torch.no_grad():\n",
        "                val_tasks = val_sampler.sample_meta_batch(meta_batch)\n",
        "                # No second-order graph for eval\n",
        "                val_loss, val_acc = maml(val_tasks, n_inner_steps=inner_steps, create_graph=False)\n",
        "\n",
        "            is_best = val_acc > best_val_acc\n",
        "            if is_best:\n",
        "                best_val_acc = val_acc\n",
        "                torch.save({\n",
        "                    \"epoch\": epoch,\n",
        "                    \"model_state\": maml.state_dict(),\n",
        "                    \"config\": {\n",
        "                        \"n_way\": n_way, \"k_shot\": k_shot, \"q_queries\": q_queries,\n",
        "                        \"in_dim\": in_dim, \"inner_steps\": inner_steps, \"inner_lr\": inner_lr,\n",
        "                        \"first_order\": first_order, \"outer_lr\": outer_lr,\n",
        "                    }\n",
        "                }, checkpoint_path)\n",
        "\n",
        "            print(\n",
        "                f\"[{epoch:04d}] \"\n",
        "                f\"train_loss(EMA)={ema_loss:.4f} | \"\n",
        "                f\"meta_acc={meta_acc:.3f} | \"\n",
        "                f\"val_loss={val_loss.item():.4f} | \"\n",
        "                f\"val_acc={val_acc:.3f} | \"\n",
        "                f\"best_val_acc={best_val_acc:.3f}\"\n",
        "            )\n",
        "\n",
        "    dt = time.time() - t0\n",
        "    print(f\"Done. Best val acc={best_val_acc:.3f}. Elapsed {dt/60:.1f} min. Checkpoint: {checkpoint_path}\")\n",
        "\n",
        "\n",
        "# ---------------------------\n",
        "# CLI\n",
        "# ---------------------------\n",
        "\n",
        "def parse_args():\n",
        "    p = argparse.ArgumentParser(description=\"MAML on synthetic Gaussian N-way K-shot classification.\")\n",
        "    p.add_argument(\"--n-way\", type=int, default=3, help=\"Number of classes per task\")\n",
        "    p.add_argument(\"--k-shot\", type=int, default=5, help=\"Support examples per class\")\n",
        "    p.add_argument(\"--q-queries\", type=int, default=15, help=\"Query examples per class\")\n",
        "    p.add_argument(\"--in-dim\", type=int, default=2, help=\"Input dimensionality\")\n",
        "    p.add_argument(\"--inner-steps\", type=int, default=5, help=\"Inner adaptation steps\")\n",
        "    p.add_argument(\"--inner-lr\", type=float, default=0.4, help=\"Inner adaptation learning rate\")\n",
        "    p.add_argument(\"--first-order\", action=\"store_true\", help=\"Use first-order MAML (no second-order grads)\")\n",
        "    p.add_argument(\"--outer-lr\", type=float, default=1e-3, help=\"Outer learning rate\")\n",
        "    p.add_argument(\"--meta-batch\", type=int, default=16, help=\"Tasks per meta-update\")\n",
        "    p.add_argument(\"--epochs\", type=int, default=3000, help=\"Number of meta-training iterations\")\n",
        "    p.add_argument(\"--val-every\", type=int, default=50, help=\"Validation interval\")\n",
        "    p.add_argument(\"--seed\", type=int, default=42, help=\"Random seed\")\n",
        "    p.add_argument(\"--device\", type=str, default=\"cuda\" if torch.cuda.is_available() else \"cpu\", help=\"Device\")\n",
        "    p.add_argument(\"--checkpoint\", type=str, default=\"./checkpoints/maml_synthetic.pt\", help=\"Checkpoint path\")\n",
        "    return p.parse_args()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    args = parse_args()\n",
        "    train_maml(\n",
        "        n_way=args.n_way,\n",
        "        k_shot=args.k_shot,\n",
        "        q_queries=args.q_queries,\n",
        "        in_dim=args.in_dim,\n",
        "        inner_steps=args.inner_steps,\n",
        "        inner_lr=args.inner_lr,\n",
        "        first_order=args.first_order,\n",
        "        outer_lr=args.outer_lr,\n",
        "        meta_batch=args.meta_batch,\n",
        "        epochs=args.epochs,\n",
        "        val_every=args.val_every,\n",
        "        seed=args.seed,\n",
        "        device=args.device,\n",
        "        checkpoint_path=args.checkpoint\n",
        "    )"
      ]
    }
  ]
}