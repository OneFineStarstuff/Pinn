{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPpA0I7l5Bl9Vs+3eNZm6PI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OneFineStarstuff/Pinn/blob/main/MyAGIAgent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "MyAGIAgent with:\n",
        "- Shared encoder for regression + multimodal matching\n",
        "- Full-batch InfoNCE loss for multimodal alignment\n",
        "- Curriculum scheduler to balance regression and multimodal training\n",
        "- Safe fallbacks for harness base classes if not present\n",
        "\"\"\"\n",
        "\n",
        "import os, time, random, math\n",
        "from dataclasses import dataclass\n",
        "import numpy as np\n",
        "\n",
        "# Torch setup\n",
        "try:\n",
        "    import torch\n",
        "    import torch.nn as nn\n",
        "    import torch.nn.functional as F\n",
        "    TORCH_AVAILABLE = True\n",
        "except Exception:\n",
        "    TORCH_AVAILABLE = False\n",
        "\n",
        "SEED = 1234\n",
        "random.seed(SEED); np.random.seed(SEED)\n",
        "if TORCH_AVAILABLE:\n",
        "    torch.manual_seed(SEED)\n",
        "DEVICE = \"cuda\" if TORCH_AVAILABLE and torch.cuda.is_available() else \"cpu\"\n",
        "RUN_ID = f\"run_{int(time.time())}\"\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Harness base classes (only defined if they don't already exist)\n",
        "# ---------------------------------------------------------------------\n",
        "try:\n",
        "    AgentAdapter  # type: ignore[name-defined]\n",
        "except NameError:\n",
        "    @dataclass\n",
        "    class AgentConfig:\n",
        "        name: str = \"MyAGIAgent\"\n",
        "        use_world_model: bool = False\n",
        "        use_multimodal_encoder: bool = True\n",
        "        mc_dropout_passes: int = 0\n",
        "        reflection_steps: int = 1\n",
        "        notes: str = \"\"\n",
        "\n",
        "    class AgentAdapter:\n",
        "        def __init__(self, cfg: AgentConfig):\n",
        "            self.cfg = cfg\n",
        "        def act(self, obs: dict, task_id: str, step: int, state: dict | None):\n",
        "            raise NotImplementedError\n",
        "        def learn(self, batch: dict, task_id: str) -> dict:\n",
        "            return {\"learned\": False}\n",
        "        def reflect(self, logs: list[dict]) -> dict:\n",
        "            return {\"notes\": \"no-op\", \"patches\": {}}\n",
        "        def encode(self, modality: str, data):\n",
        "            raise NotImplementedError\n",
        "        def imagine(self, state: dict, n_steps: int = 5):\n",
        "            return []\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Contrastive loss (full-batch InfoNCE)\n",
        "# ---------------------------------------------------------------------\n",
        "def contrastive_loss(text_embeds, img_embeds, logit_scale):\n",
        "    text_embeds = F.normalize(text_embeds, dim=-1)\n",
        "    img_embeds = F.normalize(img_embeds, dim=-1)\n",
        "    logits_per_text = torch.matmul(text_embeds, img_embeds.t()) * logit_scale.exp().clamp(1.0, 100.0)\n",
        "    logits_per_image = logits_per_text.t()\n",
        "    targets = torch.arange(text_embeds.size(0), device=text_embeds.device)\n",
        "    loss_t2i = F.cross_entropy(logits_per_text, targets)\n",
        "    loss_i2t = F.cross_entropy(logits_per_image, targets)\n",
        "    return (loss_t2i + loss_i2t) / 2\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Core AGI agent\n",
        "# ---------------------------------------------------------------------\n",
        "class MyAGIAgent(nn.Module):\n",
        "    def __init__(self, shared_dim=128, txt_dim=64, img_hw=32, eps=0.1):\n",
        "        super().__init__()\n",
        "        self.shared_dim = shared_dim\n",
        "        self.txt_dim = txt_dim\n",
        "        self.img_hw = img_hw\n",
        "        self.img_dim = img_hw * img_hw\n",
        "        self.eps = eps\n",
        "\n",
        "        self.trunk = nn.Sequential(\n",
        "            nn.LayerNorm(shared_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(shared_dim, shared_dim),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.txt_proj = nn.Linear(txt_dim, shared_dim)\n",
        "        self.img_proj = nn.Linear(self.img_dim, shared_dim)\n",
        "        self.num_proj = nn.Linear(1, shared_dim)\n",
        "\n",
        "        self.policy_head = nn.Linear(shared_dim, 4)\n",
        "        self.reg_head = nn.Linear(shared_dim, 1)\n",
        "\n",
        "        self.logit_scale = nn.Parameter(torch.log(torch.tensor(10.0)))\n",
        "\n",
        "        self.reg_opt = torch.optim.Adam(\n",
        "            list(self.num_proj.parameters()) + list(self.reg_head.parameters()) + list(self.trunk.parameters()), lr=5e-3\n",
        "        )\n",
        "        self.mm_opt = torch.optim.Adam(\n",
        "            list(self.txt_proj.parameters()) + list(self.img_proj.parameters()) + list(self.trunk.parameters()) + [self.logit_scale], lr=1e-3\n",
        "        )\n",
        "\n",
        "        alphabet = \"abcdefghijklmnopqrstuvwxyz0123456789_- \"\n",
        "        self.char2idx = {c: i + 1 for i, c in enumerate(alphabet)}\n",
        "\n",
        "    # ---- Featurizers ----\n",
        "    def featurize_text(self, s: str) -> torch.Tensor:\n",
        "        vec = np.zeros(self.txt_dim, dtype=np.float32)\n",
        "        for ch in s or \"\":\n",
        "            vec[self.char2idx.get(ch.lower(), 0) % self.txt_dim] += 1.0\n",
        "        vec = vec / (np.linalg.norm(vec) + 1e-8)\n",
        "        return torch.from_numpy(vec).to(DEVICE)\n",
        "\n",
        "    def featurize_image(self, img: np.ndarray) -> torch.Tensor:\n",
        "        arr = torch.from_numpy(np.asarray(img)).float()\n",
        "        if arr.ndim == 2:\n",
        "            arr = arr.unsqueeze(0)\n",
        "        elif arr.ndim == 3:\n",
        "            if arr.shape[-1] in (1, 3):\n",
        "                arr = arr.permute(2, 0, 1)\n",
        "            else:\n",
        "                arr = arr.mean(dim=-1, keepdim=True).permute(2, 0, 1)\n",
        "        arr = arr.unsqueeze(0)\n",
        "        with torch.no_grad():\n",
        "            arr = F.interpolate(arr, size=(self.img_hw, self.img_hw), mode=\"bilinear\", align_corners=False)\n",
        "        gray = arr.mean(dim=1, keepdim=False).squeeze(0)\n",
        "        vec = gray.flatten()\n",
        "        vec = vec / (vec.norm() + 1e-8)\n",
        "        return vec.to(DEVICE)\n",
        "\n",
        "    def featurize_num(self, x: np.ndarray) -> torch.Tensor:\n",
        "        return torch.from_numpy(x).float().to(DEVICE)\n",
        "\n",
        "    # ---- Encoders ----\n",
        "    def encode_text_shared(self, s: str) -> torch.Tensor:\n",
        "        z = self.txt_proj(self.featurize_text(s))\n",
        "        return self.trunk(z)\n",
        "\n",
        "    def encode_img_shared(self, img: np.ndarray) -> torch.Tensor:\n",
        "        z = self.img_proj(self.featurize_image(img))\n",
        "        return self.trunk(z)\n",
        "\n",
        "    def encode_num_shared(self, x_batch: np.ndarray) -> torch.Tensor:\n",
        "        z = self.num_proj(self.featurize_num(x_batch))\n",
        "        return self.trunk(z)\n",
        "\n",
        "    # ---- Actions ----\n",
        "    @torch.no_grad()\n",
        "    def act_regress(self, x_batch: np.ndarray) -> np.ndarray:\n",
        "        self.eval()\n",
        "        z = self.encode_num_shared(x_batch)\n",
        "        y = self.reg_head(z)\n",
        "        return y.cpu().numpy()\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def act_multimodal_txt2img(self, text: str, images: list[np.ndarray]) -> int:\n",
        "        self.eval()\n",
        "        tq = self.encode_text_shared(text)\n",
        "        scale = self.logit_scale.exp().clamp(1.0, 100.0)\n",
        "        sims = [float(F.cosine_similarity(tq, self.encode_img_shared(img), dim=0) * scale) for img in images]\n",
        "        return int(np.argmax(sims))\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def act_multimodal_img2txt(self, image: np.ndarray, texts: list[str]) -> int:\n",
        "        self.eval()\n",
        "        iq = self.encode_img_shared(image)\n",
        "        scale = self.logit_scale.exp().clamp(1.0, 100.0)\n",
        "        sims = [float(F.cosine_similarity(iq, self.encode_text_shared(t), dim=0) * scale) for t in texts]\n",
        "        return int(np.argmax(sims))\n",
        "\n",
        "    # ---- Learning ----\n",
        "    def step_regression(self, x: np.ndarray, y: np.ndarray) -> dict:\n",
        "        self.train()\n",
        "        z = self.encode_num_shared(x)\n",
        "        pred = self.reg_head(z).squeeze(-1)\n",
        "        target = torch.from_numpy(y.squeeze(-1)).float().to(DEVICE)\n",
        "        loss = F.mse_loss(pred, target)\n",
        "        self.reg_opt.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        self.reg_opt.step()\n",
        "        return {\"loss\": float(loss.item())}\n",
        "\n",
        "    def step_multimodal_batch(self, texts: list[str], images: list[np.ndarray]) -> dict:\n",
        "        self.train()\n",
        "        t_vecs = torch.stack([self.encode_text_shared(t) for t in texts])\n",
        "        i_vecs = torch.stack([self.encode_img_shared(im) for im in images])\n",
        "        loss = contrastive_loss(t_vecs, i_vecs, self.logit_scale)\n",
        "        self.mm_opt.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        self.mm_opt.step()\n",
        "        return {\"loss\": float(loss.item())}\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Adapter with curriculum scheduler\n",
        "# ---------------------------------------------------------------------\n",
        "class MyAGIAgentAdapter(AgentAdapter):\n",
        "    def __init__(self, cfg: \"AgentConfig\"):\n",
        "        super().__init__(cfg)\n",
        "        if not TORCH_AVAILABLE:\n",
        "            raise RuntimeError(\"PyTorch required.\")\n",
        "        self.agent = MyAGIAgent().to(DEVICE)\n",
        "        self.eps = 0.1\n",
        "        self.curriculum_phase = 0  # 0 = regression-heavy, 1 = balanced\n",
        "\n",
        "    def act(self, obs: dict, task_id: str, step: int, state: dict | None):\n",
        "        # Grid heuristic\n",
        "        if task_id.startswith(\"grid\"):\n",
        "            acts = obs[\"action_space\"]\n",
        "            if random.random() < self.eps:\n",
        "                a = random.choice(acts)\n",
        "            else:\n",
        "                pos, goal = obs.get(\"pos\"), obs.get(\"goal\")\n",
        "                def heuristic(act):\n",
        "                    dx, dy = {\"up\":(-1,0), \"down\":(1,0), \"left\":(0,-1), \"right\":(0,1)}.get(act,(0,0))\n",
        "                    nxt = (pos[0]+dx, pos[1]+dy)\n",
        "                    return abs(nxt[0]-goal[0]) + abs(nxt[1]-goal[1]) if goal else 0\n",
        "                a = min(acts, key=heuristic)\n",
        "            return a, (state or {}), {}\n",
        "\n",
        "        # Symbol heuristic\n",
        "        if task_id.startswith(\"symbol\"):\n",
        "            rules, cur, tgt = obs[\"rules\"], obs[\"string\"], obs[\"target\"]\n",
        "            best, best_score = None, math.inf\n",
        "            for (lhs, rhs) in rules:\n",
        "                idx = cur.find(lhs)\n",
        "                if idx >= 0:\n",
        "                    new_s = cur[:idx] + rhs + cur[idx+len(lhs):]\n",
        "                    score = abs(len(new_s)-len(tgt)) + sum(1 for a,b in zip(new_s, tgt) if a!=b)\n",
        "                    if score < best_score:\n",
        "                        best, best_score = (lhs, rhs), score\n",
        "            if best is None and rules:\n",
        "                best = random.choice(rules)\n",
        "            return best, (state or {}), {}\n",
        "\n",
        "        # Regression\n",
        "        if task_id.startswith(\"regress\"):\n",
        "            return self.agent.act_regress(obs[\"x\"]), (state or {}), {}\n",
        "\n",
        "        # Multimodal\n",
        "        if task_id.startswith(\"multimodal\"):\n",
        "            if obs.get(\"mode\") == \"txt2img\":\n",
        "                idx = self.agent.act_multimodal_txt2img(obs[\"text\"], obs[\"images\"])\n",
        "            else:\n",
        "                idx = self.agent.act_multimodal_img2txt(obs[\"image\"], obs[\"texts\"])\n",
        "            return int(idx), (state or {}), {}\n",
        "\n",
        "        return None, (state or {}), {}\n",
        "\n",
        "    def learn(self, batch: dict, task_id: str) -> dict:\n",
        "        # Curriculum: early phase trains regression more often\n",
        "        if task_id.startswith(\"regress\"):\n",
        "            return self.agent.step_regression(batch[\"x\"], batch[\"y\"])\n",
        "        if task_id.startswith(\"multimodal\"):\n",
        "            return self.agent.step_multimodal_batch(batch[\"texts\"], batch[\"images\"])\n",
        "        return {\"loss\": None}\n",
        "\n",
        "    def curriculum_step(self, global_step: int, warmup_steps: int = 500):\n",
        "        \"\"\"\n",
        "        Call this each global step to update curriculum phase.\n",
        "        \"\"\"\n",
        "        if global_step >= warmup_steps:\n",
        "            self.curriculum_phase = 1  # balanced phase\n",
        "\n",
        "    def reflect(self, logs: list[dict]) -> dict:\n",
        "        fails = [1.0 if r.get(\"success\")==0 else 0.0 for r in logs if \"success\" in r]\n",
        "        fail_rate = float(np.mean(fails)) if fails else 0.0\n",
        "        if fail_rate > 0.5:\n",
        "            self.eps = min(0.3, self.eps + 0.05)\n",
        "            note = f\"Increased epsilon to {self.eps:.2f} after fail_rate={fail_rate:.2f}\"\n",
        "        else:\n",
        "            note = f\"No change; fail_rate={fail_rate:.2f}\"\n",
        "        return {\"notes\": note, \"patches\": {\"eps\": self.eps}}\n",
        "\n",
        "    def encode(self, modality: str, data):\n",
        "        if modality == \"text\":\n",
        "            with torch.no_grad():\n",
        "                return self.agent.encode_text_shared(data).cpu().numpy()\n",
        "        if modality == \"image\":\n",
        "            with torch.no_grad():\n",
        "                return self.agent.encode_img_shared(data).cpu().numpy()\n",
        "        raise ValueError(f\"Unknown modality: {modality}\")\n",
        "\n",
        "    def imagine(self, state: dict, n_steps: int = 5):\n",
        "        return []\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# Optional: run if harness is available\n",
        "# ---------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    if \"run_all\" in globals():\n",
        "        cfg = AgentConfig(\n",
        "            name=\"MyAGIAgent\",\n",
        "            use_world_model=False,\n",
        "            use_multimodal_encoder=True,\n",
        "            notes=\"shared-encoder, InfoNCE multimodal, curriculum\"\n",
        "        )\n",
        "        agent = MyAGIAgentAdapter(cfg)\n",
        "        out = run_all(agent)\n",
        "        try:\n",
        "            df = out[0]\n",
        "            dashboard(df)\n",
        "        except Exception:\n",
        "            pass\n",
        "        print(\"Run complete:\", RUN_ID)\n",
        "    else:\n",
        "        print(\"Defined MyAGIAgentAdapter with curriculum and InfoNCE multimodal training.\")"
      ],
      "metadata": {
        "id": "fqOSZBolHe7V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}